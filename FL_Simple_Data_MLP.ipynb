{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FL_Simple_Data_MLP",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMzug8mx/9F7mjkJkgjQChy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunghwan-moon/2021_capstone_BrainAgePrediction_by_Federated_Learning/blob/main/FL_Simple_Data_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWwyNIZgvJkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "931b26ac-db37-4c42-d2c3-38c5d08b2630"
      },
      "source": [
        "!pip install tensorflow_federated\n",
        "#!pip install nilearn\n",
        "#!pip install transformations\n",
        "!pip install nest_asyncio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_federated in /usr/local/lib/python3.7/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (1.19.5)\n",
            "Requirement already satisfied: tensorflow~=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (2.5.0)\n",
            "Requirement already satisfied: tqdm~=4.28.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (4.28.1)\n",
            "Requirement already satisfied: attrs~=19.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (19.3.0)\n",
            "Requirement already satisfied: semantic-version~=2.8.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (2.8.5)\n",
            "Requirement already satisfied: tensorflow-model-optimization~=0.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (0.1.6)\n",
            "Requirement already satisfied: jaxlib~=0.1.55 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (0.1.66+cuda110)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (1.34.1)\n",
            "Requirement already satisfied: retrying~=1.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (1.3.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (0.12.0)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (1.3.9)\n",
            "Requirement already satisfied: cachetools~=3.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (3.1.1)\n",
            "Requirement already satisfied: jax~=0.2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (0.2.13)\n",
            "Requirement already satisfied: tensorflow-privacy~=0.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated) (0.5.2)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (1.1.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (2.5.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5.0->tensorflow_federated) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib~=0.1.55->tensorflow_federated) (1.4.1)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow_federated) (1.2.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow~=2.5.0->tensorflow_federated) (1.5.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow~=2.5.0->tensorflow_federated) (57.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (1.30.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (4.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5.0->tensorflow_federated) (0.4.8)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uOzLyzTvJm2"
      },
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import threading\n",
        "from random import gauss\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "import operator\n",
        "from scipy.ndimage.interpolation import shift,rotate\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.ndimage as nd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score,mean_absolute_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import sys\n",
        "import random\n",
        "import glob\n",
        "import nibabel as nib\n",
        "from collections import defaultdict\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "#from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, add, concatenate,GlobalAveragePooling3D,Conv3D,LeakyReLU,ELU, MaxPooling3D,AveragePooling3D\n",
        "from tensorflow.keras.regularizers import l2 as L2\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from tensorflow.keras.optimizers import Adam, SGD,Adagrad\n",
        "from keras.engine.topology import Layer\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Input, InputLayer, InputSpec\n",
        "#from tensorflow.keras import backend as K\n",
        "#from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "#import tensorflow.compat.v1 as tf\n",
        "# tf.compat.v1.enable_v2_behavior()\n",
        "# tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "from tensorflow.compat.v1 import keras\n",
        "from tensorflow.compat.v1.keras.layers import Dense, Dropout, Activation, Flatten, Input, add, concatenate,GlobalAveragePooling3D,Conv3D,LeakyReLU,ELU, MaxPooling3D,AveragePooling3D\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSI_JnviudUC",
        "outputId": "b0a4b6e7-8a8d-425d-c619-e71b4c1921e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpVB6bHuMc3P"
      },
      "source": [
        "def getData(path):\n",
        "  original_data = pd.read_excel(path)\n",
        "  original_data.dropna(inplace=True)\n",
        "  original_data.drop([\"ID\",\"Sex\"], axis = 1, inplace=True)\n",
        "\n",
        "  train, test = train_test_split(original_data, test_size = 0.2, random_state =100)\n",
        "\n",
        "\n",
        "  x_train = train.drop([\"Age\"],axis=1).to_numpy(np.float32)\n",
        "  y_train = train[\"Age\"].to_numpy(np.float32)\n",
        "\n",
        "  x_test = test.drop([\"Age\"],axis=1).to_numpy(np.float32)\n",
        "  y_test = test[\"Age\"].to_numpy(np.float32)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPRODWkRLDm3"
      },
      "source": [
        "x_train, y_train, x_test, y_test = getData('/content/drive/MyDrive/소융_캡스톤/뇌 MRI 사진_교수님/IXI_train_test_age.xlsx')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqhxxqsmREuk",
        "outputId": "08008497-bceb-4935-bc39-b2ea739e4a65"
      },
      "source": [
        "num_train_image = len(x_train)\n",
        "num_test_image= len(x_test)\n",
        "print(\"Train set: \", num_train_image)\n",
        "print(\"Test set: \", num_test_image)\n",
        "print(\"Train set Shape: \", x_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set:  370\n",
            "Test set:  93\n",
            "Train set Shape:  (370, 69)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASN3hSWJmpVr"
      },
      "source": [
        "#client Data Non-iid 형태로 만들기 // 중복X\n",
        "\n",
        "def Make_data_to_Non_RE_Client_data(num_train_image, Client_num, x_train, y_train):\n",
        "  client_train_dataset = collections.OrderedDict()\n",
        "  partition_Start = 0\n",
        "  partition_End = int(num_train_image/Client_num - 1)\n",
        "\n",
        "  for i in range(0, Client_num):\n",
        "    client_key = \"client_\" + str(i+1) # client_1, client_2 .....\n",
        "\n",
        "    train_data = collections.OrderedDict((('features', x_train[partition_Start:partition_End]),('label', y_train[partition_Start:partition_End])))\n",
        "    client_train_dataset[client_key] = train_data\n",
        "    partition_Start = partition_End + 1\n",
        "    partition_End = int(partition_End + num_train_image/Client_num - 1)\n",
        "\n",
        "  #tensorSliceClientData를 simulation의 instance로 변환\n",
        "  train_dataset = tff.simulation.datasets.TestClientData(client_train_dataset)\n",
        "\n",
        "  return train_dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX_FEmmWyFmX"
      },
      "source": [
        "#client Data Non-iid 형태로 만들기 // 중복 허용\n",
        "\n",
        "def Make_data_to_RE_Client_data(num_train_image, Client_num, x_train, y_train):\n",
        "  client_train_dataset = collections.OrderedDict()\n",
        "  Client_num = 4\n",
        "  for i in range(0, Client_num):\n",
        "    client_key = \"client_\" + str(i+1) # client_1, client_2 .....\n",
        "\n",
        "  # non-iid를 위한 random sampling\n",
        "    front_train = random.randint(1, num_train_image)\n",
        "    rear_train = random.randint(front_train, num_train_image)\n",
        "\n",
        "    train_data = collections.OrderedDict((('features', x_train[front_train:rear_train]),('label', y_train[front_train:rear_train])))\n",
        "    client_train_dataset[client_key] = train_data\n",
        "\n",
        "  #tensorSliceClientData를 simulation의 instance로 변환\n",
        "  train_dataset = tff.simulation.datasets.TestClientData(client_train_dataset)\n",
        "\n",
        "  return train_dataset"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5_BZzFUk4S3"
      },
      "source": [
        "#총 Client 수 결정\n",
        "\n",
        "Original_Client_data = Make_data_to_Non_RE_Client_data(num_train_image, 4, x_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEzdKf7RJiUP"
      },
      "source": [
        "# 각 Client 별로 학습할 데이터 추출\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 100 #각 Client가 가질 데이터 수\n",
        "SHUFFLE_BUFFER = 10\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.reshape(element[\"features\"], [-1,69]),\n",
        "        y=tf.reshape(element[\"label\"], [-1, 1]))\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).prefetch(PREFETCH_BUFFER).map(batch_format_fn)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwLkZsUYJiWY"
      },
      "source": [
        "def make_federated_data(client_data, client_ids):\n",
        "  result_list = []\n",
        "  for id in client_ids:\n",
        "    preprocess_data = preprocess(client_data.create_tf_dataset_for_client(id))\n",
        "    sample = tf.nest.map_structure(lambda x: x.numpy(),next(iter(preprocess_data)))\n",
        "    result_list.append(preprocess_data)\n",
        "  print(\"Each client data size : \", len(sample[\"y\"]))\n",
        "  return result_list"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuY_ubCZ5SsU",
        "outputId": "84a735b5-9aa2-4e04-9c6a-a7b09f6a4972"
      },
      "source": [
        "sample_clients = Original_Client_data.client_ids[0:4]\n",
        "\n",
        "federated_train_data = make_federated_data(Original_Client_data, sample_clients)\n",
        "\n",
        "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
        "print('First dataset: {d}'.format(d=federated_train_data[0]))\n",
        "print(\"input_spec : {n}\".format(n = federated_train_data[0].element_spec))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Each client data size :  100\n",
            "Number of client datasets: 4\n",
            "First dataset: <MapDataset shapes: OrderedDict([(x, (None, 69)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.float32)])>\n",
            "input_spec : OrderedDict([('x', TensorSpec(shape=(None, 69), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpCKcz3_Sh1J"
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "   layers.Dense(1, input_shape=(69,), activation = 'linear'),\n",
        "   layers.Dense(10),\n",
        "   layers.Dense(5),\n",
        "   layers.Dense(1, activation=\"relu\")\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqNBXSI1J1ul"
      },
      "source": [
        "def model_fn():\n",
        "    keras_model = build_model()\n",
        "    return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=federated_train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.MeanAbsoluteError(),\n",
        "      metrics=[tf.keras.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc2XHN_nJ1xF"
      },
      "source": [
        "def initialize_fn():\n",
        "  model = model_fn()\n",
        "  return model.trainable_variables"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TA7GiihL8w2"
      },
      "source": [
        "def next_fn(server_weights, federated_dataset):\n",
        "  server_weights_at_client = broadcast(server_weights)\n",
        "  client_weights = client_update(federated_dataset, server_weights_at_client)\n",
        "  mean_client_weights = mean(client_weights)\n",
        "  server_weights = server_update(mean_client_weights)\n",
        "  \n",
        "  return server_weights"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U62TEoSGJ1zg"
      },
      "source": [
        "@tf.function\n",
        "def client_update(model, dataset, server_weights, client_optimizer):\n",
        "  print(\"client_update tf.fn\")\n",
        "  client_weights = model.trainable_variables\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        client_weights, server_weights)\n",
        "  \n",
        "  for batch in dataset:\n",
        "      with tf.GradientTape() as tape:\n",
        "        outputs = model.forward_pass(batch)\n",
        "\n",
        "      grads = tape.gradient(outputs.loss, client_weights)\n",
        "      grads_and_vars = zip(grads, client_weights)\n",
        "\n",
        "      client_optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "  return client_weights"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW43-L6XMsp_"
      },
      "source": [
        "@tf.function\n",
        "def server_update(model, mean_client_weights):\n",
        "  model_weights = model.trainable_variables\n",
        "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
        "                        model_weights, mean_client_weights)\n",
        "  return model_weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R9AlzSoM68n"
      },
      "source": [
        "@tff.tf_computation\n",
        "def server_init():\n",
        "  model = model_fn()\n",
        "  return model.trainable_variables"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRTAvFYSNLWw"
      },
      "source": [
        "@tff.federated_computation\n",
        "def initialize_fn():\n",
        "  return tff.federated_value(server_init(),tff.SERVER)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKU83IOARr4Q"
      },
      "source": [
        "tf_dataset_type = tff.SequenceType(model_fn().input_spec)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FXXONLj2tJD7",
        "outputId": "beae15cc-888c-43f4-b002-301ed4e32420"
      },
      "source": [
        "str(tf_dataset_type)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<x=float32[?,69],y=float32[?,1]>*'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayeRWd3iPv-1"
      },
      "source": [
        "model_weights_type = server_init.type_signature.result"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "m2_pNGxwtLzT",
        "outputId": "bf9781ee-5b67-4ffb-ef87-ee88cf19053f"
      },
      "source": [
        "str(model_weights_type)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<float32[69,1],float32[1],float32[1,10],float32[10],float32[10,5],float32[5],float32[5,1],float32[1]>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fodKTfXYjgQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a7c719-25a6-49f8-cfab-e7826f77569f"
      },
      "source": [
        "@tff.tf_computation(tf_dataset_type, model_weights_type)\n",
        "def client_update_fn(tf_dataset, server_weights):\n",
        "  model = model_fn()\n",
        "  client_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) #Adam, SGD\n",
        "  return client_update(model, tf_dataset, server_weights, client_optimizer)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "client_update tf.fn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjH5-w__P-f3"
      },
      "source": [
        "@tff.tf_computation(model_weights_type)\n",
        "def server_update_fn(mean_client_weights):\n",
        "  model = model_fn()\n",
        "  return server_update(model, mean_client_weights)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOt9z2szQByy"
      },
      "source": [
        "federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n",
        "federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2GLH0pKutrQ-",
        "outputId": "62925e5f-9707-4ee3-c957-968cab33175c"
      },
      "source": [
        "str(federated_dataset_type)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{<x=float32[?,69],y=float32[?,1]>*}@CLIENTS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf81urj0ttyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e98be86e-2081-4e1e-de8e-eed2707a391e"
      },
      "source": [
        "str(federated_server_type)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<float32[69,1],float32[1],float32[1,10],float32[10],float32[10,5],float32[5],float32[5,1],float32[1]>@SERVER'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LusuOlaQDUu"
      },
      "source": [
        "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
        "def next_fn(server_weights, federated_dataset):\n",
        "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
        "  client_weights = tff.federated_map(\n",
        "        client_update_fn, (federated_dataset, server_weights_at_client))\n",
        "  mean_client_weights = tff.federated_mean(client_weights)\n",
        "  server_weights = tff.federated_map(server_update_fn, mean_client_weights)\n",
        "\n",
        "  return server_weights"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP8sJ7iTQHhq"
      },
      "source": [
        "federated_algorithm = tff.templates.IterativeProcess(\n",
        "      initialize_fn=initialize_fn,\n",
        "      next_fn=next_fn\n",
        "    )"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaTdm9mRQSEt"
      },
      "source": [
        "def evaluate(server_state):\n",
        "  keras_model = build_model()\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.MeanAbsoluteError(),\n",
        "      metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
        "  )\n",
        "  keras_model.evaluate(x=x_test, y=y_test, batch_size=5)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJLr7i0pQYMd"
      },
      "source": [
        "server_state = federated_algorithm.initialize()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTOKj6MGzuZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ded044-63a2-4e2d-93c3-191124df69d2"
      },
      "source": [
        "evaluate(server_state)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 0s 1ms/step - loss: 50.0730 - mean_absolute_error: 50.0730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2GFFLyxdOpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbca3b9b-4f12-4763-d900-4be1737cbd22"
      },
      "source": [
        "for round in range(10):\n",
        "  print(\"round \",round+1)\n",
        "  server_state = federated_algorithm.next(server_state, federated_train_data)\n",
        "  print(\"\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round  1\n",
            "\n",
            "round  2\n",
            "\n",
            "round  3\n",
            "\n",
            "round  4\n",
            "\n",
            "round  5\n",
            "\n",
            "round  6\n",
            "\n",
            "round  7\n",
            "\n",
            "round  8\n",
            "\n",
            "round  9\n",
            "\n",
            "round  10\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAJyDzJ6manm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358a06d0-5bf1-41a4-f37e-586ba88bb3a1"
      },
      "source": [
        "evaluate(server_state)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 0s 1ms/step - loss: 47.5459 - mean_absolute_error: 47.5459\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}